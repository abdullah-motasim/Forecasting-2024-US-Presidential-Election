% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={My title},
  pdfauthor={Abdullah Motasim; Elizabeth Luong},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{My title\thanks{Code and data are available at:
\url{https://github.com/abdullah-motasim/Forecasting-2024-US-Presidential-Election}.}}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{My subtitle if needed}
\author{Abdullah Motasim \and Elizabeth Luong}
\date{November 4, 2024}

\begin{document}
\maketitle
\begin{abstract}
First sentence. Second sentence. Third sentence. Fourth sentence.
\end{abstract}

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\section{Introduction}\label{introduction}

Overview paragraph: On November 5 2024 the U.S. Presidential Elections
will be held to determine the 47th President of the United States. Since
the U.S. is a powerhouse within the world, often affecting crucial
international affairs, the result of this election will have a global
impact on all countries and as such there is much interest in which of
the top two candidates Donald Trump or Kamala Harris will end up winning
the election. As such, leading up to the election time there are many
polls conducted by different pollsters to determine the winner of the
election, but these polls often vary significantly between each other
due to biases and sampling limitations. Poll aggregation is a method
which aims to mitigate these differences by combining or aggregating the
results of multiple polls to provide a more robust estimate of the
election outcome.

This study seeks to forecast the 2024 U.S. Presidential election outcome
by developing a generalized linear model based on poll aggregation data.
Specifically, we evaluate predictors including demographics, polling
trends, and historical voting patterns. While the popular vote does not
directly determine the presidential outcome due to the electoral college
system, our model's findings offer a clearer picture of voter
preferences and potential trends in key states. This paper outlines our
modeling approach, data processing techniques, and results, with a final
section discussing model limitations and implications for future
election forecasting.

Estimand paragraph: The primary estimand in this study is the
probability of a Democratic or Republican victory in the popular vote,
based on current polling trends and demographic predictors.

Results paragraph: State results of who won in which state (the 5 in
exploratory) and also talk about the final model and who it predicted to
win in each state on the day of the election than also who won overall.

Why it matters paragraph:

Telegraphing paragraph: The remainder of this paper is structured as
follows. Section~\ref{sec-data}\ldots.

\section{Data}\label{sec-data}

\subsection{Overview}\label{overview}

The aggregated dataset containing the polling data for the 2024 U.S.
election was sourced from FiveThrityEight (). We use the statistical
programming language R (R Core Team 2023) and packages the \ldots{} to
download, analyze, and model the data.

The initial raw data contained about 17000 observations of 52 variables
from multiple pollsters and after cleaning the data we were left with
about 9000 observations of 7 variables. The data cleaning involved
removing missing values and only selecting variables which were of
importance to us, these variables were:

\begin{itemize}
\item
  \textbf{pollster\_name} - The name of the polling organization that
  conducted the poll (e.g., YouGov, RMG Research).
\item
  \textbf{candidate} - The name of the candidate in the poll (e.g.,
  Kamala Harris, Donald Trump).
\item
  \textbf{percentage} - The percentage of the vote or support that the
  candidate received in the poll (e.g., 51.0 for Kamala Harris, 48.0 for
  Donald Trump).
\item
  \textbf{party} - The political party of the candidate in the poll
  (e.g., DEM for Democrats, REP for Republicans).
\item
  \textbf{sample\_size} - The total number of respondents participating
  in the poll (e.g., 2712).
\item
  \textbf{state} - The U.S. state where the poll was conducted or
  focused, if applicable.
\item
  \textbf{numeric\_grade} - A numeric rating given to the pollster to
  indicate their quality or reliability (e.g., 3.0).
\end{itemize}

These variables were selected due to their direct relevance to assessing
candidate support, polling reliability, and geographic voting trends.
Specifically, pollster\_name and numeric\_grade are crucial for tracking
potential biases and variations across polling organizations, as
different methodologies can impact results. Candidate/Party and
percentage provide direct indicators of support levels for each
contender, which is essential for making accurate projections of
election outcomes. Also, it is worth noting that there were more
Sample\_size is key to assessing the reliability of each poll, as larger
samples tend to yield more accurate representations of public opinion.
Lastly, state enables us to account for regional variations, crucial in
a system like the U.S. Electoral College, where state-level results play
a determining role in the election. Collectively, these variables offer
a focused and comprehensive view of the polling landscape, supporting a
more reliable aggregation and interpretation of the data.

\subsection{Measurement}\label{measurement}

Since different pollsters utilize various methods to collect their data
and convert real-world phenomena into entries in their datasets, we have
chosen to focus on the method utilized by Emerson, as it is the most
frequent pollster within our cleaned data, accounting for 823 of the
observations. Analyzing Emerson's methodology provides valuable insights
into how polling results are generated, thereby enhancing our
understanding of the dataset.

Emerson College Polling employs a combination of Interactive Voice
Response (IVR) and online panel methodologies for data collection. The
recent survey of Michigan sampled 1,000 likely voters. Emerson developed
a series of survey questions to ask these potential candidates such as
do you prove or disapprove of the job Joe Biden is doing as president?
What is your party registration? etc. After this the results of the
survey are analyzed to get the percentages of votes for each option and
these are than presented within the aggregated data set.

Note this is a general overview of the measurement method utilized by
Emerson, a more thorough breakdown of measurement can be found in
{[}Appendix A{]}.

\subsection{Outcome variables}\label{outcome-variables}

Add graphs, tables and text. Use sub-sub-headings for each outcome
variable or update the subheading to be singular.

Some of our data is of penguins (\textbf{?@fig-bills}), from Horst,
Hill, and Gorman (2020).

Talk more about it.

And also planes (\textbf{?@fig-planes}). (You can change the height and
width, but don't worry about doing that until you have finished every
other aspect of the paper - Quarto will try to make it look nice and the
defaults usually work well once you have enough text.)

Talk way more about it.

\subsection{Predictor variables}\label{predictor-variables}

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine
a few into one if they go together naturally.

\section{Model}\label{model}

This analysis uses Bayesian Generalized Linear Models (GLM) with
Gaussian distributions to predict the support percentages for Kamala
Harris and Donald Trump across multiple polls. The continuous outcome
variable, representing the predicted support percentage, is modeled as a
function of key predictors to capture poll-specific and demographic
variations.

Background details and diagnostics are included in
Appendix~\ref{sec-model-details}.

\subsection{Model set-up}\label{model-set-up}

Given the continuous nature of support percentages, a Gaussian family
with an \textbf{identity link function} was selected. This choice allows
the model to accurately estimate continuous variations in support
percentages, adjusting for effects from pollster, sample size, and
state. The model can be expressed as follows:

\[\text{Support Percentage} = \beta_0 + \beta_1 \cdot \text{pollster} + \beta_2 \cdot \text{sample size} + \beta_3 \cdot \text{state}\]
Where:

\begin{itemize}
\item
  \(\beta_0\) is the intercept term
\item
  \(\beta_1\) represents the effect of the pollster source.
\item
  \(\beta_2\) captures the influence of the sample size on support
  percentage.
\item
  \(\beta_3\) accounts for state-level variations.
\end{itemize}

\subsection{Explaination of Variables and
Inclusions}\label{explaination-of-variables-and-inclusions}

Each predictor in the model is chosen for its relevance in reflecting
the polling data's characteristics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Pollster (\texttt{pollster})}: Captures potential systematic
  differences among organizations, ensuring that support estimates are
  not bias by any single pollster's methodology.
\item
  \textbf{Sample Size (\texttt{sample\_size})}: Accounts for the
  reliability of each poll, as larger samples tend to reduce margin of
  error.
\item
  \textbf{State (\texttt{state})}: Controls for geographic and political
  variations, allowing the model to adjust for differences in support
  based on regional preferences.
\end{enumerate}

The summary statistics below (\textbf{SummaryStatisticsComparison?})
outline key variables in our analysis, focusing on Kamala Harris and
Donald Trump. These tables display the distribution of support
percentages and sample sizes, with metrics including mean, median,
standard deviation, minimum, and maximum.

\begin{longtable}[t]{l>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}>{\raggedleft\arraybackslash}p{2em}}
\caption{Directly compares support percentages and sample sizes for Harris and
Trump, showing central tendencies and variability in polling data for
each candidate.}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{5}{c}{Percentage Statistics} & \multicolumn{2}{c}{Sample Size Statistics} \\
\cmidrule(l{3pt}r{3pt}){2-6} \cmidrule(l{3pt}r{3pt}){7-8}
Candidate & Mean & Median & SD & Min & Max & Sample Size Mean & Sample Size SD\\
\midrule
Kamala Harris & 47.32 & 47.6 & 4.46 & 25 & 70 & 910.86 & 544.67\\
Donald Trump & 45.56 & 46.0 & 5.37 & 21 & 70 & 879.21 & 524.25\\
\bottomrule
\end{longtable}

\subsection{Model justification}\label{model-justification}

\subsubsection{Bayesian Framework}\label{bayesian-framework}

The models utilize a Bayesian approach with normal priors on the
coefficients, implemented through the \texttt{rstanarm} package of
Goodrich et al. (2022) in R (R Core Team 2023). The Bayesian framework
offers two primary advantages for our analysis:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Uncertainty Representation}: Posterior distributions for each
  coefficient provide a clear indication of uncertainty around the
  estimates, allowing for more informative predictions.
\item
  \textbf{Regularization}: Normal priors help stabilize estimates,
  especially for smaller sample sizes or polls with limited data points,
  reducing overfitting.
\end{enumerate}

\subsubsection{Monte Carlo Simulation for Win Probability
Estimation}\label{monte-carlo-simulation-for-win-probability-estimation}

To assess the probability of each candidate winning, we employed Monte
Carlo simulations using posterior predictions from the GLMs:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Generate Posterior Predictions}: Posterior distributions from
  each candidate's model produce a range of possible support percentages
  for Harris and Trump.
\item
  \textbf{Simulate Election Outcomes}: Each simulation iteration
  compares Harris' and Trump's predicted support. Harris is marked as
  the winner if her support surpasses Trump's, and vice versa.
\item
  \textbf{Estimate Win Probabilities}: By repeating this comparison over
  thousands of iterations, we estimate win probabilities for each
  candidate based on the frequency of simulated wins.
\end{enumerate}

\subsection{Model Assumptions and
Limitations}\label{model-assumptions-and-limitations}

The Bayesian Generalized Linear Models in this analysis have key
assumptions and limitations that may impact predictive accuracy.

First, the assumption of a Gaussian distribution for support percentages
may not fully capture the true nature of polling data, particularly if
the data include skewness or outliers. While a Gaussian distribution
efficiently models continuous support, it may lead to biased estimates
in smaller states or in polls with high variance if non-normal patterns
are present.

Second, the model assumes that each pollster's effect on support
estimates is consistent across all states, disregarding potential
variations in polling methodologies and accuracy by region. This
simplification may overlook regional nuances, especially if certain
pollsters perform differently in specific states, potentially reducing
accuracy in cases of state-specific polling practices.

Finally, the model treats state-level effects as static, assuming that
state-specific support remains stable over time. This limits the model's
ability to adapt to changing voter sentiment within states as the
election nears. Significant state-level shifts that occur after the
latest data collection may not be reflected in the predictions, leading
to outdated estimates.

While these assumptions balance interpretability and reliability, they
also indicate areas for future improvement, such as dynamic state
effects and region-specific pollster adjustments, to further enhance
predictive accuracy.

\section{Results}\label{results}

The results of the Bayesian Generalized Linear Model (GLM) analysis,
which aimed to predict support percentages for Kamala Harris and Donald
Trump across various polls. The findings, represented through
probability estimates, predicted support distributions, and comparative
density plots, provide insights into each candidate's likely performance
in hypothetical head-to-head polling scenarios.

\subsection{Predicted Support
Percentages}\label{predicted-support-percentages}

\subsubsection{Kamala Harris}\label{kamala-harris}

The distribution of predicted support for Kamala Harris is displayed in
Figure 4. The model estimates her average support at approximately
47.32\%, with the majority of values clustering around this mean. This
relatively tight distribution indicates consistent support for Harris
across polls, with limited variability. The standard deviation of her
predicted support suggests that her polling results remain stable, even
in states with more diverse polling outcomes.

\subsubsection{Donald Trump}\label{donald-trump}

Figure 5 illustrates the predicted support for Donald Trump, centered
around a mean of 45.56\%. Compared to Harris, Trump's predicted support
distribution shows slightly greater variability, indicating a broader
spread in his support across polls. The higher standard deviation in
Trump's support highlights increased variability in polling outcomes,
suggesting a wider range of voter responses depending on the region and
poll characteristics.

\subsubsection{Comparison of Predicted
Support}\label{comparison-of-predicted-support}

The combined density plot in Figure 6 provides a direct comparison of
Harris and Trump's predicted support distributions. Harris's
distribution (in blue) peaks at a higher level than Trump's (in red),
indicating her slight edge in predicted support. Both distributions
overlap significantly, particularly between 45\% and 50\%, underscoring
the close nature of their polling outcomes. This overlap suggests that
while Harris holds a predicted lead, the margins are slim, indicating a
competitive scenario in many states.

\subsection{Probability of Winning}\label{probability-of-winning}

Using Monte Carlo simulation, we estimated the likelihood of each
candidate securing a win based on their predicted support. According to
the model, Harris has a 63.2\% probability of winning, while Trump has a
36.8\% probability. These probabilities were calculated by comparing
predicted support across thousands of iterations, with each iteration
counting a win for the candidate who garnered higher support. This
probabilistic approach captures the uncertainty inherent in election
predictions and emphasizes Harris' modest advantage in a hypothetical
head-to-head match-up.

\subsection{State-Specific Trends}\label{state-specific-trends}

\subsubsection{Regional Variation in
Support}\label{regional-variation-in-support}

The model reveals notable differences in support by state, aligning with
known regional preferences. For instance, Harris' support is
consistently higher in traditionally Democratic states like California
and New York, where her predicted vote share surpasses 60\%. Conversely,
Trump shows strong predicted support in states like Texas and Florida,
with anticipated leads of 5-10 percentage points, reflecting historical
Republican preferences.

\subsubsection{Battleground States}\label{battleground-states}

In critical battleground states like Pennsylvania and Ohio, the
predicted support for both candidates is nearly evenly split, signifying
highly competitive races. The model suggests that Trump may hold a
slight edge in Ohio, while Harris appears to lead narrowly in
Pennsylvania. These projections highlight the importance of minor
polling shifts in these states, where even small changes in support
could significantly influence the final outcome.

\subsection{Summary of Predicted
Insights}\label{summary-of-predicted-insights}

Overall, the model's results showcase the impact of state-level factors,
polling characteristics, and candidate-specific trends on predicted
outcomes. The Bayesian GLM, enhanced with Monte Carlo simulations,
enables the estimation of win probabilities and predicted support with a
quantifiable degree of uncertainty. Harris' predicted advantage, while
modest, is supported by stable polling across states, whereas Trump's
broader distribution points to more variable support, especially in key
states. This analysis provides a foundation for understanding
competitive dynamics and regional differences in the 2024 U.S.
presidential race, with implications for candidate strategies in
battleground states.

Our results are summarized in Table~\ref{tbl-modelresults}.

\section{Discussion - Predictive Modeling of 2024 Election
Outcomes}\label{discussion---predictive-modeling-of-2024-election-outcomes}

\subsection{Key Findings}\label{key-findings}

The analysis utilizes Bayesian Generalized Linear Models (GLMs) and
Monte Carlo simulations to estimate predicted support percentages for
Kamala Harris and Donald Trump. With a win probability of 63.2\% for
Harris and 36.8\% for Trump, the model suggests a modest advantage for
Harris, albeit within a competitive margin. The density plot (Fig. 6)
highlights the distributions of predicted support for both candidates,
showing a slight overlap, which indicates close competition and
underscores the uncertainty inherent in forecasting elections based on
polling data.

Our findings emphasize the roles of pollster reliability, sample size,
and state-level effects in influencing predicted support. Specifically,
the distributions of predicted support (Figs. 4 and 5) reveal that both
Harris and Trump have a strong central tendency around similar support
percentages, with Harris showing a slightly higher mean. This slight
advantage for Harris in the distribution of predicted support aligns
with her higher win probability. However, the narrowness of this
advantage indicates that slight variations in support could easily alter
the projected outcome.

\subsection{Influence of Sample Size and Pollster
Effects}\label{influence-of-sample-size-and-pollster-effects}

The results suggest that larger sample sizes generally produce more
stable support estimates, reducing the influence of random fluctuations
in polling data. Polls with larger sample sizes are less likely to
exhibit extreme support values, which improves the reliability of the
predictions. However, smaller sample sizes tend to introduce
variability, often exaggerating support levels for one candidate. For
instance, in battleground states with smaller sample sizes, our model
indicates higher variability in support percentages, which could lead to
overestimated support in certain cases. Thus, integrating sample size as
a predictor helps moderate these extremes and improves the precision of
predictions.

Pollster effects are also significant in this analysis. Different
pollsters have unique methodologies, sampling techniques, and weighting
schemes, which can lead to systematic differences in reported support.
By including pollster as a predictor in the model, we control for these
variations, allowing for a more standardized comparison of support
across polls. This inclusion reduces the likelihood that any single
pollster's methodology disproportionately skews the predictions,
resulting in more balanced estimates across different polls.

\subsection{State-Level Variations in
Support}\label{state-level-variations-in-support}

The model highlights the importance of state-level effects, revealing
that support for each candidate varies significantly by region. For
example, Harris is shown to have strong support in traditionally
Democratic states, whereas Trump maintains a lead in Republican-leaning
regions. In battleground states such as Florida and Pennsylvania, the
predicted support percentages are closer, reflecting the competitive
nature of these regions. The density plot in Fig. 6 illustrates that
while Harris has a slight overall advantage, support for both candidates
closely overlaps in key states, indicating that regional factors are
pivotal in determining final outcomes.

Our results underscore the necessity of including state-level predictors
to capture these regional nuances. Ignoring state-level effects could
oversimplify the model, potentially misrepresenting the strength of
support for each candidate in different parts of the country. By
accounting for these variations, our model can provide a more nuanced
prediction that aligns with observed state-specific voting patterns.

\subsection{Weaknesses}\label{weaknesses}

While the models presented provide a comprehensive approach to
forecasting the 2024 election, both the data and models have inherent
weaknesses that may impact the accuracy of the predictions.

\subsubsection{Data-Related Weaknesses}\label{data-related-weaknesses}

The polling data used in this analysis, while comprehensive, presents
challenges in terms of representativeness and variability. Polls differ
widely in sample size, methodology, and quality, which can introduce
biases that are difficult to adjust for consistently across states. For
instance, smaller sample sizes, particularly in less-populated or
battleground states, may lead to exaggerated or unstable estimates of
support. Additionally, polling firms often adopt different weighting
schemes or sampling frames, which may not fully capture the demographic
and geographic diversity within each state. This variability can result
in inconsistencies when aggregating polls across different regions,
potentially skewing the predictions for states with sparse polling data.

Another challenge is the limited frequency of polling in certain
regions. Many states receive minimal polling attention, leading to
sparse data that may not accurately reflect shifts in voter sentiment
over time. This lack of consistent polling can cause the model to rely
on outdated or unrepresentative data points, especially in states where
political dynamics are changing rapidly. Consequently, the model may
overestimate or underestimate support in these areas, reducing the
accuracy of the overall predictions.

\subsubsection{Model-Related Weaknesses}\label{model-related-weaknesses}

The model's reliance on a Gaussian distribution to predict support
percentages may not fully account for the non-normality often observed
in polling data. Polling data can exhibit skewed distributions or heavy
tails, particularly in states where support for a candidate is highly
polarized. By assuming a Gaussian distribution, the model may miss these
nuances, potentially leading to biased estimates in states where the
distribution of support is not symmetric.

Additionally, the model assumes that the effect of each pollster on
support estimates is consistent across all states, an assumption that
may oversimplify regional differences in polling accuracy. Different
pollsters have varying levels of reliability in specific regions,
influenced by factors like local sampling techniques, demographic
targeting, and survey timing. By treating pollster effects as uniform,
the model may fail to capture these subtleties, potentially resulting in
inaccurate support estimates for states where polling practices differ
significantly.

The static nature of the state-level effects in the model also presents
a limitation. Political dynamics within states are fluid, particularly
in the lead-up to an election, when voter sentiment may shift rapidly in
response to events, campaigns, or emerging issues. By treating
state-level effects as constant, the model lacks the flexibility to
account for these temporal changes. Consequently, predictions based on
older polls may not accurately reflect current support levels,
especially in states with fast-changing political landscapes.

\subsubsection{Impact on Prediction
Accuracy}\label{impact-on-prediction-accuracy}

These data and model weaknesses underscore the challenges of election
forecasting and highlight the potential for misestimations in certain
regions. The variability in polling data quality and the assumption of
static state effects may reduce the model's predictive accuracy,
particularly in battleground states where small shifts in voter
sentiment could have a significant impact on the election outcome.
Furthermore, the lack of temporal adaptation in the model may lead to
outdated predictions as the election approaches, particularly if there
are last-minute shifts in public opinion.

\subsection{Future Directions}\label{future-directions}

To enhance the predictive accuracy of election forecasting models,
future research could focus on several key improvements. One promising
avenue is the integration of time-series elements to account for
temporal changes in voter sentiment as election day approaches. A
time-series approach would allow the model to weigh recent polls more
heavily than older data, reflecting shifts in public opinion as new
events, debates, and campaign efforts unfold. This would result in a
more dynamic model that adapts to real-time changes in voter
preferences, increasing prediction accuracy closer to election day.

Incorporating voter turnout predictions based on historical data and
demographic trends could further improve the model's reliability.
Turnout often varies by demographic group, driven by factors such as
candidate appeal, mobilization efforts, and election-specific conditions
like weather. Adjusting predictions based on turnout likelihoods by
group would create a more nuanced view of potential election outcomes,
especially in swing states where voter turnout can significantly impact
results.

Expanding the Bayesian framework to incorporate historical voting
patterns as informative priors would be particularly valuable in states
with sparse or inconsistent polling. Bayesian methods can update
predictions as new polling data becomes available, grounding predictions
in past election trends while allowing flexibility for current shifts.
This approach would mitigate the volatility often seen in states with
limited data, leading to more stable estimates.

Finally, integrating alternative data sources, such as social media
sentiment analysis or economic indicators, could enrich the model by
capturing real-time shifts in voter sentiment not reflected in
traditional polling. For instance, social media activity following major
events like debates or policy announcements could serve as an indicator
of changes in support, supplementing polling data to create a more
responsive forecasting model. Economic indicators, such as unemployment
rates or inflation, could also offer insights into voter priorities and
potential support patterns, enhancing the model's predictive capacity in
economically sensitive regions.

Implementing these advancements would address current data and model
limitations, creating a more adaptive and robust forecasting tool
capable of accurately capturing the complexities of voter behavior in a
dynamic election landscape.

\subsection{Conclusion}\label{conclusion}

The analysis demonstrates that both pollster reliability and sample size
are critical factors in accurately predicting support percentages, while
state-specific effects capture essential regional variations. However,
the model's assumptions and limitations suggest avenues for further
refinement. Incorporating dynamic, turnout-adjusted, and multi-source
data into future models could yield more precise election forecasts. In
sum, while this model provides a solid foundation for understanding
potential outcomes in the 2024 election, continuous refinement and
adaptation to new data sources and methods will enhance the reliability
of election prediction models.

\newpage

\appendix

\section*{Appendix}\label{appendix}
\addcontentsline{toc}{section}{Appendix}

\section{Pollster Methodology Overview and
Evaluation}\label{pollster-methodology-overview-and-evaluation}

The Emerson College Polling method utilizes a hybrid approach, combining
Interactive Voice Response (IVR) with an online panel to gather data
from likely voters in Michigan. This methodology is crucial in
translating individual opinions into quantifiable data that can inform
electoral forecasts and insights.

\textbf{Population, Frame, and Sample}\\
The target population is defined as the collection of all items about
which we would like to speak, in this case it would be all voters in the
state of Michigan.

The sampling frame defined as a list of all the items from the target
population that we could get data about, in this case it would be all
voters who are able to respond to the IVR or online panel survey

A sample is defined as the items from the sampling frame that we get
data about, in this case that would be the 1000 people that responded to
the ICR or online panel.

\textbf{Sample Recruitment and Sampling Approach}\\
Emerson employs both IVR and online panel methodologies to recruit
participants. The IVR method facilitates automated phone interviews,
reaching demographics that may be less likely to participate in online
surveys, such as older individuals or those with limited internet
access. In contrast, the online panel is sourced from CINT, engaging
participants who are more willing to complete surveys digitally. This
dual approach captures a broader spectrum of voter sentiments and
demographics, balancing the advantages of both methods. However, while
IVR can access hard-to-reach populations, it may also yield lower
response rates compared to the more engaged online panel.

\textbf{Non-response Handling}\\
While the IVR method can reach various demographics, it is essential to
consider potential non-response bias. Respondents who opt not to
participate may share similar characteristics, leading to skewed
results. Emerson may implement follow-up strategies or incentives to
encourage participation, but these measures are not explicitly detailed
in the methodology.

\textbf{Questionnaire Evaluation}\\
Emerson crafted a comprehensive questionnaire that included a range of
questions, such as ``Do you approve or disapprove of the job Joe Biden
is doing as President?'' and ``What is your party registration?''
Respondents provided their answers using multiple-choice formats,
offering options like ``Approve,'' ``Disapprove,'' ``Neutral or no
opinion,'' as well as party affiliations such as ``Democrat,''
``Republican,'' and ``Independent/other.'' The full questionnaire and
its results can be accessed at this
\href{https://docs.google.com/spreadsheets/d/1QxGDC4nSP1dS6N7N1aXBxnXkRPyfw2As/edit?gid=1716322793\#gid=1716322793}{link}.
After collecting the responses, the results were tallied to calculate
the percentage for each option, enabling pollsters to convert individual
opinions into broader trends. While the questions are generally clear
and allow for straightforward responses, careful consideration should be
given to the wording to avoid any potential bias. Questions that lead
respondents toward a particular answer could impact the validity of the
data collected.

\textbf{Overview of Methodology}

\begin{itemize}
\item
  \textbf{Data Collection Techniques:} Emerson employs both IVR and
  online panel methodologies. IVR allows for automated phone interviews,
  which can reach a diverse demographic, including those less likely to
  participate in online surveys. The online panel, sourced from CINT,
  complements this by engaging participants who are more accessible and
  willing to complete surveys digitally. This dual approach is intended
  to capture a broad spectrum of voter sentiments and demographics.
\item
  \textbf{Sample Size and Credibility:} The survey includes a sample of
  1,000 likely voters, providing a reasonable basis for statistical
  inference. Emerson states a credibility interval of ±3 percentage
  points, which indicates a moderate level of precision in their
  estimates. This credibility interval should be considered when
  interpreting results, as it reflects the potential variability in
  public opinion.
\item
  \textbf{Weighting Adjustments:} To ensure that the sample accurately
  reflects the population of likely voters, the data is weighted by
  gender, education, race, age, party registration, and region. This
  weighting is critical, as it aligns the sample with demographic
  characteristics of the actual voter population, enhancing the
  reliability of the findings.
\end{itemize}

\textbf{Strengths of the Methodology}

\begin{itemize}
\item
  \textbf{Diverse Reach:} The combination of IVR and online panel
  methods allows Emerson to capture data from a wide range of
  demographics, minimizing the risk of bias that may arise from using a
  single method. This is particularly important in a politically diverse
  state like Michigan.
\item
  \textbf{Rigorous Weighting:} The meticulous approach to weighting the
  data helps to correct any imbalances in the sample, ensuring a more
  accurate reflection of voter sentiments across different demographic
  groups.
\item
  \textbf{Clarity in Reporting:} Emerson provides detailed demographic
  breakdowns and cross-tabulations, allowing for a nuanced understanding
  of how different groups perceive key issues and candidates.
\end{itemize}

\textbf{Limitations of the Methodology}

\begin{itemize}
\item
  \textbf{Potential Non-response Bias:} While the IVR method can reach
  various demographics, those who opt not to participate may share
  similar characteristics, potentially leading to non-response bias.
  Additionally, the online panel may attract a skewed sample if certain
  demographics are overrepresented or underrepresented in the panel.
\item
  \textbf{Higher Credibility Intervals for Subgroups:} Subsets based on
  demographics (e.g., age or party registration) often come with larger
  credibility intervals due to smaller sample sizes. This can diminish
  the reliability of conclusions drawn from those specific groups.
\item
  \textbf{Temporal Limitations:} The survey results reflect a snapshot
  of opinions at a specific time (October 25-27, 2024), which may not
  account for rapidly changing political landscapes, particularly as
  Election Day approaches.
\end{itemize}

In summary, Emerson College Polling employs a robust methodology that
effectively combines IVR and online panel methodologies to gauge voter
sentiment. While there are inherent limitations, such as potential
biases and the credibility of subgroup analysis, the strengths of this
approach lie in its comprehensive reach and careful weighting
adjustments. Overall, this methodology offers a valuable tool for
understanding the current political climate in Michigan.

\section{Idealized Survey}\label{idealized-survey}

In this appendix, I outline an idealized methodology and survey for
forecasting the U.S. presidential election, utilizing a budget of
\$100,000. This approach combines robust sampling techniques, diverse
recruitment strategies, and thorough data validation to ensure accurate
and reliable insights into voter sentiment.

\textbf{Sampling Approach}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Target Population}: The target population consists of
  registered voters in the United States. The survey will focus on
  likely voters, including individuals aged 18 and older across various
  demographic groups, including age, gender, race, and political
  affiliation.
\item
  \textbf{Sample Size}: A sample size of approximately 5,000 likely
  voters will be utilized. This sample size is designed to provide a
  high level of statistical confidence, with a credibility interval of
  ±2 percentage points.
\item
  \textbf{Sampling Technique}:

  \begin{itemize}
  \item
    A \textbf{stratified random sampling} method will be employed to
    ensure representation across key demographic groups. The population
    will be divided into strata based on demographic variables, such as
    age, gender, race, and region.
  \item
    A systematic selection will then be conducted within each stratum to
    achieve a balanced representation, reducing sampling bias.
  \end{itemize}
\end{enumerate}

\textbf{Recruitment of Respondents}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Data Sources}:

  \begin{itemize}
  \item
    Voter registration databases will be utilized to identify potential
    respondents. These databases will provide contact information for
    registered voters across the United States.
  \item
    Partnerships with organizations that specialize in voter engagement
    will also be established to enhance the recruitment process.
  \end{itemize}
\item
  \textbf{Recruitment Methods}:

  \begin{itemize}
  \item
    \textbf{Online Panel}: An online panel sourced from reputable survey
    platforms (e.g., SurveyMonkey, Qualtrics) will be used to recruit
    respondents who opt-in to participate in surveys.
  \item
    \textbf{IVR and SMS Outreach}: Interactive Voice Response (IVR) and
    SMS outreach will be implemented to reach demographics that may be
    less likely to engage in online surveys. This will ensure
    inclusivity and broaden the reach of the survey.
  \end{itemize}
\item
  \textbf{Incentives}: Participants will be incentivized to complete the
  survey with small monetary rewards (e.g., \$5) or entry into a raffle
  for a larger prize, thereby increasing response rates and engagement.
\end{enumerate}

\textbf{Data Validation and Quality Assurance}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Pre-Survey Testing}: A pilot test of the survey will be
  conducted with a smaller group of respondents (approximately 200) to
  identify any ambiguities or biases in the questions. Feedback will be
  incorporated to refine the survey instrument.
\item
  \textbf{Quality Checks}:

  \begin{itemize}
  \item
    During data collection, real-time monitoring will be implemented to
    identify and address any inconsistencies in responses.
  \item
    Automated checks will flag any duplicate responses, incomplete
    surveys, or inconsistent answer patterns.
  \end{itemize}
\item
  \textbf{Post-Survey Validation}: After data collection, a validation
  process will be employed to cross-reference responses with demographic
  data to ensure the sample reflects the broader population accurately.
\end{enumerate}

\textbf{Poll Aggregation and Analysis}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Data Aggregation}: The data will be aggregated and analyzed
  using statistical software (e.g., R or Python) to compute margins of
  error and establish confidence intervals for key questions, such as
  candidate approval ratings and voting intentions.
\item
  \textbf{Cross-Tabulation}: The survey results will be cross-tabulated
  by demographic variables to provide insights into how different groups
  perceive candidates and issues. This will enable nuanced analysis of
  voter sentiment across demographics.
\item
  \textbf{Reporting}: Findings will be compiled into a comprehensive
  report summarizing key insights, trends, and forecasts for the
  upcoming presidential election. The report will be shared with
  stakeholders, including political analysts and campaign teams.
\end{enumerate}

\textbf{Survey Implementation}

The survey will be implemented using Google Forms. Below is a link to
the actual survey, which includes an introductory section,
well-constructed questions, and a closing section thanking respondents
for their participation:

\href{https://docs.google.com/forms/d/e/1FAIpQLSdlSVq77BK3tKqsrsdLZicLx8ie0Jei1PFX3HzOGmpKxolD8w/viewform?usp=sf_link}{\textbf{U.S.
Presidential Election Forecasting Survey}}

\textbf{Survey Copy}

\textbf{U.S. Presidential Election Forecasting Survey}

\textbf{Introduction}

Thank you for participating in our survey! Your insights are invaluable
for understanding voter sentiment leading up to the upcoming US
presidential election. This survey will take approximately 5-10 minutes
to complete. Your responses are anonymous and will be used solely for
research purposes.

If you have any questions or concerns, please contact Elizabeth Luong at
elizabethh.luong@mail.utoronto.ca.

\textbf{Section 1: Demographic Information}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{What is your age?}

  \begin{itemize}
  \item
    Under 18
  \item
    18-24
  \item
    25-34
  \item
    35-44
  \item
    45-54
  \item
    55-64
  \item
    65 or older
  \end{itemize}
\item
  \textbf{What is your gender?}

  \begin{itemize}
  \item
    Male
  \item
    Female
  \item
    Non-binary/Third gender
  \item
    Prefer not to say
  \end{itemize}
\item
  \textbf{What is your race or ethnicity:}

  \begin{itemize}
  \item
    White
  \item
    Black or African American
  \item
    Asian
  \item
    Hispanic or Latino
  \item
    Other (please specify): {[}Open text field{]}
  \end{itemize}
\item
  \textbf{In which state do you reside?}

  \begin{itemize}
  \tightlist
  \item
    {[}Open text field{]}
  \end{itemize}
\item
  \textbf{What is your highest level of education completed?}

  \begin{itemize}
  \item
    Some high school
  \item
    High school diploma or equivalent
  \item
    Some college
  \item
    Bachelor's degree
  \item
    Graduate degree
  \end{itemize}
\item
  \textbf{What is your party affiliation?}

  \begin{itemize}
  \item
    Democrat
  \item
    Republican
  \item
    Independent
  \item
    Other (please specify): {[}Open text field{]}
  \end{itemize}
\end{enumerate}

\textbf{Section 2: Political Opinions}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\item
  \textbf{How likely are you to vote in the upcoming presidential
  election?}

  \begin{itemize}
  \item
    Very likely
  \item
    Somewhat likely
  \item
    Unsure
  \item
    Somewhat unlikely
  \item
    Very unlikely
  \end{itemize}
\item
  \textbf{Which candidate do you plan to vote for in the upcoming
  presidential election?}

  \begin{itemize}
  \item
    Donald Trump (Republican)
  \item
    Kamala Harris (Democrat)
  \item
    Robert F. Kennedy Jr.~(Independent)
  \item
    Undecided
  \item
    Other (please specify): {[}Open text field{]}
  \end{itemize}
\item
  \textbf{What are the most important issues influencing your vote?}
  (Select up to three)

  \begin{itemize}
  \item
    Economy
  \item
    Healthcare
  \item
    Education
  \item
    Climate Change
  \item
    Social Justice
  \item
    National Security
  \item
    Immigration
  \item
    Other (please specify): {[}Open text field{]}
  \end{itemize}
\item
  \textbf{How do you feel about the job performance of the current
  President?}

  \begin{itemize}
  \item
    Strongly approve
  \item
    Approve
  \item
    Neutral
  \item
    Disapprove
  \item
    Strongly disapprove
  \end{itemize}
\end{enumerate}

\textbf{Section 3: Media Consumption}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\item
  \textbf{Which sources do you primarily use to get news about the
  election?} (Select all that apply)

  \begin{itemize}
  \item
    Television
  \item
    Online news websites
  \item
    Social media
  \item
    Radio
  \item
    Newspapers
  \item
    Podcasts
  \item
    Other (please specify): {[}Open text field{]}
  \end{itemize}
\item
  \textbf{How often do you discuss politics with friends and family?}

  \begin{itemize}
  \item
    Daily
  \item
    Weekly
  \item
    Monthly
  \item
    Rarely
  \item
    Never
  \end{itemize}
\end{enumerate}

\textbf{Conclusion}

Thank you for taking the time to complete this survey! Your feedback is
crucial for understanding voter sentiment as we approach the election.
If you have any additional comments or thoughts you'd like to share,
please reach out to~Elizabeth Luong at
elizabethh.luong@mail.utoronto.ca.

\textbf{Thank you again for your participation!}

\section{Additional data details}\label{additional-data-details}

\section{Model details}\label{sec-model-details}

\subsection{Posterior predictive
check}\label{posterior-predictive-check}

In \textbf{?@fig-ppcheckandposteriorvsprior-1} we implement a posterior
predictive check. This shows\ldots{}

In \textbf{?@fig-ppcheckandposteriorvsprior-2} we compare the posterior
with the prior. This shows\ldots{}

\begin{figure}

\begin{minipage}{0.50\linewidth}
Examining how the model fits, and is affected by, the
data\end{minipage}%

\end{figure}%

\subsection{Diagnostics}\label{diagnostics}

\textbf{?@fig-stanareyouokay-1} is a trace plot. It shows\ldots{} This
suggests\ldots{}

\textbf{?@fig-stanareyouokay-2} is a Rhat plot. It shows\ldots{} This
suggests\ldots{}

\begin{figure}

\begin{minipage}{0.50\linewidth}
Checking the convergence of the MCMC algorithm\end{minipage}%

\end{figure}%

\newpage

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-rstanarm}
Goodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022.
{``{rstanarm: {Bayesian} applied regression modeling via {Stan}}.''}
\url{https://mc-stan.org/rstanarm/}.

\bibitem[\citeproctext]{ref-palmerpenguins}
Horst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020.
\emph{{palmerpenguins: Palmer Archipelago (Antarctica) penguin data}}.
\url{https://doi.org/10.5281/zenodo.3960218}.

\bibitem[\citeproctext]{ref-citeR}
R Core Team. 2023. \emph{{R: A Language and Environment for Statistical
Computing}}. Vienna, Austria: R Foundation for Statistical Computing.
\url{https://www.R-project.org/}.

\end{CSLReferences}




\end{document}
